"""
Author:      XuLin Yang
Student id:  904904
Date:        
Description: https://medium.com/@violante.andre/simple-reinforcement-learning-temporal-difference-learning-e883ea0d65b0

I think we should use TD(1) because 1 makes our agent long term reward considered
which means it becomes monte carlo method by https://blog.csdn.net/weixin_37895339/article/details/74644038

TD is better than monte carlo: https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce

for all about monte carlo, TD (on/off policy)
https://medium.com/deep-math-machine-learning-ai/ch-12-1-model-free-reinforcement-learning-algorithms-monte-carlo-sarsa-q-learning-65267cb8d1b4

"""


class TDAgent:
    pass

